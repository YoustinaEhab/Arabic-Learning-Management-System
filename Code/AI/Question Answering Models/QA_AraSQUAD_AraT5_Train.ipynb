{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install torch>=2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU transformers datasets optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_json(\"/kaggle/input/arabic-squad-v20/asquadv2-train.json\", encoding='ISO-8859-1')\n",
    "validation_data = pd.read_json(\"/kaggle/input/arabic-squad-v20/asquadv2-val.json\", encoding='ISO-8859-1')\n",
    "test_data = pd.read_json(\"/kaggle/input/arabic-squad-v20/asquadv2-test.json\", encoding='ISO-8859-1')\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Normalize and clean data\n",
    "def normalize_data(data):\n",
    "    data = pd.json_normalize(data['data'], ['paragraphs', 'qas'], ['title', ['paragraphs', 'context']])\n",
    "    data = data.rename(columns={'paragraphs.context': 'context', 'question': 'question', 'answers': 'answers'})\n",
    "    data['answers'] = data['answers'].apply(lambda x: {'text': [x[0]['text']] if x else [], 'answer_start': [x[0]['answer_start']] if x else []})\n",
    "    data = data[data[\"is_impossible\"] == False].drop(['is_impossible', 'plausible_answers'], axis=1, errors='ignore')\n",
    "    return data\n",
    "\n",
    "train_data = normalize_data(train_data)\n",
    "validation_data = normalize_data(validation_data)\n",
    "test_data = normalize_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Extract relevant fields\n",
    "def extract_relevant_data(dataset):\n",
    "    return pd.DataFrame({\n",
    "        \"context\": dataset[\"context\"],\n",
    "        \"question\": dataset[\"question\"],\n",
    "        \"answer\": dataset[\"answers\"].apply(lambda ans: ans[\"text\"][0] if ans[\"text\"] else \"\")\n",
    "    })\n",
    "\n",
    "train_data = extract_relevant_data(train_data)\n",
    "validation_data = extract_relevant_data(validation_data)\n",
    "test_data = extract_relevant_data(test_data)\n",
    "\n",
    "# Check lengths\n",
    "print(f\"Train data size: {len(train_data)}\")\n",
    "print(f\"Validation data size: {len(validation_data)}\")\n",
    "print(f\"Test data size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "import pandas as pd\n",
    "def format_for_answer_generation(dataset):\n",
    "    return pd.DataFrame({\n",
    "        \"text\": \"<context>\" + dataset[\"context\"] + \"<question>\" + dataset[\"question\"],\n",
    "        \"required\": \"<answer>\" + dataset[\"answer\"]\n",
    "    })\n",
    "# Process training data\n",
    "train_ag = format_for_answer_generation(train_data)\n",
    "train_ag_dataset = Dataset.from_pandas(train_ag)\n",
    "\n",
    "# Process validation data\n",
    "val_ag = format_for_answer_generation(validation_data)  # Assuming val_data exists\n",
    "val_ag_dataset = Dataset.from_pandas(val_ag)\n",
    "\n",
    "# Process test data\n",
    "test_ag = format_for_answer_generation(test_data)  \n",
    "test_ag_dataset = Dataset.from_pandas(test_ag)\n",
    "\n",
    "\n",
    "# Create dataset dictionary including train, validation, and test sets\n",
    "datasets_ag = DatasetDict({\n",
    "    \"train\": train_ag_dataset,\n",
    "    \"validation\": val_ag_dataset,\n",
    "    \"test\": test_ag_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets_ag['train'] = datasets_ag['train'].remove_columns(['__index_level_0__'])\n",
    "datasets_ag['validation'] = datasets_ag['validation'].remove_columns(['__index_level_0__'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets_ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "datasets_ag[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, GenerationConfig\n",
    "\n",
    "# model_name = \"UBC-NLP/AraT5-base\"\n",
    "model_name = \"UBC-NLP/AraT5v2-base-1024\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    padding=True,  # Dynamically pad to the longest in the batch\n",
    "    label_pad_token_id=-100  # Ensures padded tokens in labels don't affect training\n",
    ")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"text\"],  # Input: Context\n",
    "        max_length=768,  # Limit input length\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",  # Ensures uniform input size\n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        examples[\"required\"],  # Output: Target\n",
    "        max_length=30,  # Target length is much shorter\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"  # Ensures uniform output size\n",
    "    )\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# tokenized_qg_datasets = datasets_qg.map(tokenize_function, batched=True, remove_columns=[\"text\", \"required\"])\n",
    "tokenized_ag_datasets = datasets_ag.map(tokenize_function, batched=True, remove_columns=[\"text\", \"required\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(type(tokenized_ag_datasets))  # Should be <class 'datasets.dataset_dict.DatasetDict'>\n",
    "print(tokenized_ag_datasets)  # Prints dataset details\n",
    "print(tokenized_ag_datasets[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to decode and print input and labels\n",
    "def print_decoded_example(dataset, split, index):\n",
    "    print(f\"\\nExample from {split} split (index {index}):\")\n",
    "    print(\"Decoded input:\", tokenizer.decode(dataset[split][index][\"input_ids\"]))\n",
    "    print(\"Decoded labels:\", tokenizer.decode(dataset[split][index][\"labels\"]))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Print examples from train, validation, and test splits\n",
    "print_decoded_example(tokenized_ag_datasets, \"train\", 200)  # First example from training set\n",
    "print_decoded_example(tokenized_ag_datasets, \"validation\", 2)  # First example from validation set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to check special tokens\n",
    "def check_special_tokens(tokenizer):\n",
    "    print(\"\\nSpecial tokens:\")\n",
    "    print(f\"<context>: {tokenizer.convert_tokens_to_ids('<context>')}\")\n",
    "    print(f\"<answer>: {tokenizer.convert_tokens_to_ids('<answer>')}\")\n",
    "    print(f\"<question>: {tokenizer.convert_tokens_to_ids('<question>')}\")\n",
    "    print(f\"</s>: {tokenizer.convert_tokens_to_ids('</s>')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define special tokens\n",
    "special_tokens_dict = {\"additional_special_tokens\": [\"<context>\", \"<answer>\", \"<question>\"]}\n",
    "\n",
    "# Add them to the tokenizer\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Check again\n",
    "check_special_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qU  wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "# !huggingface-cli login --token {'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'}\n",
    "wandb.login(key='77eafacbf29d3f89b810de78fe1f766a9b6e6fe8')\n",
    "\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Resize model embeddings if needed (only if using a model)\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Check for NaN or inf in the dataset\n",
    "# import numpy as np\n",
    "\n",
    "# def check_for_invalid_values(dataset):\n",
    "#     for split in dataset:\n",
    "#         print(f\"Checking {split} split...\")\n",
    "#         for example in dataset[split]:\n",
    "#             if np.isnan(example[\"input_ids\"]).any() or np.isinf(example[\"input_ids\"]).any():\n",
    "#                 print(f\"Invalid input_ids found in {split} split!\")\n",
    "#             if np.isnan(example[\"labels\"]).any() or np.isinf(example[\"labels\"]).any():\n",
    "#                 print(f\"Invalid labels found in {split} split!\")\n",
    "\n",
    "# check_for_invalid_values(tokenized_ag_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Decode a few examples to verify tokenization\n",
    "for i in range(3):\n",
    "    print(f\"\\nExample {i + 1}:\")\n",
    "    print(\"Input IDs:\", tokenized_ag_datasets[\"train\"][i][\"input_ids\"])\n",
    "    print(\"Decoded Input:\", tokenizer.decode(tokenized_ag_datasets[\"train\"][i][\"input_ids\"]))\n",
    "    print(\"Labels:\", tokenized_ag_datasets[\"train\"][i][\"labels\"])\n",
    "    print(\"Decoded Labels:\", tokenizer.decode(tokenized_ag_datasets[\"train\"][i][\"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_preds):\n",
    "#     \"\"\"\n",
    "#     Compute F1, Precision, Recall for Hugging Face Trainer.\n",
    "#     Uses Arabic-aware token-level matching.\n",
    "#     \"\"\"\n",
    "#     preds, labels = eval_preds\n",
    "\n",
    "#     # Replace -100 in labels with pad token id\n",
    "#     labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n",
    "\n",
    "#     # Optionally: clip preds to tokenizer vocab size (avoids huge token ids)\n",
    "#     preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n",
    "\n",
    "#     try:\n",
    "#         decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#         decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "#     except Exception as e:\n",
    "#         print(\"‚ùå Error during decoding:\", e)\n",
    "#         print(\"Preds type:\", type(preds), \"Shape:\", preds.shape)\n",
    "#         print(\"Labels type:\", type(labels), \"Shape:\", labels.shape)\n",
    "#         raise e\n",
    "\n",
    "#     f1s, precisions, recalls = [], [], []\n",
    "\n",
    "#     for pred, label in zip(decoded_preds, decoded_labels):\n",
    "#         pred_tokens = set(arabic_tokenize(pred))\n",
    "#         label_tokens = set(arabic_tokenize(label))\n",
    "\n",
    "#         tp = len(pred_tokens & label_tokens)\n",
    "#         precision = tp / len(pred_tokens) if pred_tokens else 0\n",
    "#         recall = tp / len(label_tokens) if label_tokens else 0\n",
    "#         f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "#         f1s.append(f1)\n",
    "#         precisions.append(precision)\n",
    "#         recalls.append(recall)\n",
    "\n",
    "#     print(f\"üîç Sample prediction: {decoded_preds[0]}\")\n",
    "#     print(f\"‚úÖ Sample label:      {decoded_labels[0]}\")\n",
    "#     print(f\"üìä F1: {np.mean(f1s):.4f}, Precision: {np.mean(precisions):.4f}, Recall: {np.mean(recalls):.4f}\")\n",
    "\n",
    "#     return {\n",
    "#         \"f1\": np.mean(f1s),\n",
    "#         \"precision\": np.mean(precisions),\n",
    "#         \"recall\": np.mean(recalls),\n",
    "#     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-23T17:52:41.563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from transformers import (\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    ")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./finetuned-AraT5-QA\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    predict_with_generate=True,\n",
    "    weight_decay=0.01,\n",
    "    # save_total_limit=2,\n",
    "    num_train_epochs=15,\n",
    "    fp16=False,  # Disable mixed precision for debugging\n",
    "    generation_num_beams=3,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True  # Uncommented to load the best model at the end\n",
    ")\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Shuffle before selecting the subset\n",
    "train_dataset = tokenized_ag_datasets[\"train\"].shuffle(seed=seed).select(range(min(20000, len(tokenized_ag_datasets[\"train\"]))))\n",
    "val_dataset = tokenized_ag_datasets[\"validation\"].shuffle(seed=seed).select(range(min(2000, len(tokenized_ag_datasets[\"validation\"]))))\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "# Before training\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-06-23T17:52:41.563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model(\"./arat5_qa\")\n",
    "tokenizer.save_pretrained(\"./arat5_qa\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6828613,
     "sourceId": 10973974,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
